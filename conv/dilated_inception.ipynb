{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dilated_inception(nn.Module):\n",
    "    def __init__(self, cin, cout, dilation_factor=2):\n",
    "        super().__init__()\n",
    "        self.tconv = nn.ModuleList()\n",
    "        self.kernel_set = [2,3,6,7]\n",
    "        cout = int(cout/len(self.kernel_set))\n",
    "        for kern in self.kernel_set:\n",
    "            self.tconv.append(nn.Conv2d(cin, cout, (1, kern), dilation=(1, dilation_factor)))\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = []\n",
    "        for i in range(len(self.kernel_set)):\n",
    "            x.append(self.tconv[i](input))\n",
    "        for i in range(len(self.kernel_set)):\n",
    "            x[i] = x[i][..., -x[-1].size(3):]\n",
    "        x = torch.cat(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = nn.Conv2d(10,30,(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 10, 8])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t(torch.randn(1, 10, 10, 10)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(1,2,3,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4, 5])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].size(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graph_constructor(nn.Module):\n",
    "    def __init__(self, nnodes, k, dim, device, alpha=3, static_feat=None):\n",
    "        super().__init__()\n",
    "        self.nnodes = nnodes\n",
    "        if static_feat is not None:\n",
    "            xd = static_feat.shape[1]\n",
    "            self.lin1 = nn.Linear(xd, dim)\n",
    "            self.lin2 = nn.Linear(xd, dim)\n",
    "        else:\n",
    "            self.emb1 = nn.Embedding(nnodes, dim)\n",
    "            self.emb2 = nn.Embedding(nnodes, dim)\n",
    "            self.lin1 = nn.Linear(dim, dim)\n",
    "            self.lin2 = nn.Linear(dim, dim)\n",
    "        self.device = device\n",
    "        self.k = k\n",
    "        self.dim = dim\n",
    "        self.alpha = alpha\n",
    "        self.static_feat = static_feat\n",
    "\n",
    "    def forward(self, idx):\n",
    "        if self.static_feat in None:\n",
    "            nodevec1 = self.emb1(idx)\n",
    "            nodevec2 = self.emb2(idx)\n",
    "        else:\n",
    "            nodevec1 = self.static_feat[idx, :]\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class gtnet(nn.Module):\n",
    "    def __init__(self, ...):\n",
    "        self.gconv1 = nn.ModuleList()\n",
    "        self.gconv2 = nn.ModuleList()\n",
    "        \n",
    "        self.start_conv = nn.Conv2d(in_channels=in_dim,\n",
    "                                    out_channels=r)\n",
    "        self.gc = graph_constructor(num_nodes, subgraph_size, node_dim,\n",
    "                                    device, alpha=tanhalpha, static_feat=static_feat)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(1):\n",
    "            ...\n",
    "            for j in range(1,layers+1):\n",
    "                if dilation_exponential > 1:\n",
    "                    ...\n",
    "                else:\n",
    "                    ...\n",
    "\n",
    "                self.filter_convs.append(dilated_inception(residual_channels, conv_channels, \n",
    "                                                           dilation_factor=new_dilation))\n",
    "                self.gate_convs.append(dilated_inception(residual_channels, conv_channels,\n",
    "                                                         dilation_factor=new_dilation))\n",
    "                self.residual_convs.append(nn.Conv2d())\n",
    "\n",
    "                # [B,conv_ch,T] => [B, skip_ch, 1]\n",
    "                if self.seq_length > self.receptive_field:\n",
    "                    self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n",
    "                                                     out_channels=skip_channels,\n",
    "                                                     kernel_size=(1, self.seq_length-rf_size_j+1)))\n",
    "                else:\n",
    "                    self.skip_convs.append(nn.Conv2d(in_channels=conv_channels,\n",
    "                                                     out_channels=skip_channels,\n",
    "                                                     kernel_size=(1, self.receptive_field-rf_size_j+1)))\n",
    "\n",
    "                if self.gcn_true:\n",
    "                    self.gconv1.append()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0041225012c46a81f6ea3650572d975902102d8f41a1704402cdfe5d667efe52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
