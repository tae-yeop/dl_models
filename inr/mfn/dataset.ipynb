{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/3dfm/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiteam/miniconda3/envs/3dfm/lib/python3.8/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "coords = torch.stack(torch.meshgrid([torch.linspace(-1.0, 1.0, 256), \n",
    "                                     torch.linspace(-1.0, 1.0, 256)]), dim=-1).view(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFNBase(nn.Module):\n",
    "    def __init__(self, hidden_size, out_size,\n",
    "                 n_layers, weight_scale, bias=True, output_act=False):\n",
    "        super().__init__()\n",
    "        self.linear = nn.ModuleList([nn.Linear(hidden_size, hidden_size, bias) for _ in range(n_layers)])\n",
    "\n",
    "        self.output_linear = nn.Linear(hidden_size, out_size)\n",
    "        self.output_act = output_act\n",
    "\n",
    "        for lin in self.linear:\n",
    "            lin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CameraDataset(Dataset):\n",
    "    def __init__(self, side_length=None):\n",
    "        self.image = Image.fromarray(skimage.data.camera())\n",
    "\n",
    "        if side_length is None:\n",
    "            self.side_length = self.image.shape[-1]\n",
    "        self.side_length = side_length\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3dfm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0041225012c46a81f6ea3650572d975902102d8f41a1704402cdfe5d667efe52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
